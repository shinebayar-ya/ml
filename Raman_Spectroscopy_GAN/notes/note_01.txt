# Raman Spectral

Танилцуулга
Олон янзын орчинд бодисыг Раман спектрт үндэслэн хурдан бөгөөд ихэвчлэн их хэмжээгээр тодорхойлох нийтлэг хэрэгцээ байдаг.

Machine classification нь бодит хугацаанд бол сайн ажилдаг ч асуудал нь өгөгдөлдөө урьдчилсан боловсруулалт хийдэг нь үнэн төвөгтэй хэвээр байгаа юм. Тэгээд энэ нь peak detection ч юм уу эсвэл multivariate method эдр байх нь ямар ч хамаагүй хийх л шаардлагатай гэсэн үг. За тэгээд pipeline буюу machine classification -руу оруулдаг хоолой гэж ойлгож болно. Энэ хоолойгоор явахдаа нэг хэд хэдэн үйлдлийг хийдэг. Тэдгээрт болохоор илүү дутуу буруу юм хум хавчуулагдсан эсэхийн шалгадаг жишээ нь сансрын цацраг ч юм уу тэ
тэгээд тиймэрхүү зүйлсийн устганаа. Өөр гэхийн бол бас ер нь бид хэд чухал зүйлээ барьж авах шаардлагатай тийм учраас smoothing буюу гөлгөржүүлэх, тэгшлэх гэж монгол руу буугаад байгаан за тэгээд юу ч юм байгаан baseline correction гэдэг data prepocessing хийгээд байдаг гэж байгаан. Эдгээр үйлдлийг багцлаад өөр бусад юмнууд хийх үйлдлийг тэр pipeline буюу хоолойгоор дамжих үйл явц гэж ойлгож байгаа. Мөн тэгээд dimension буюу feature -н тоо эсвэл өгөгдлийн баганын тоо гэх юм уу тэр зүйлийг багасгахын тулд PCA гэдэг зүйлийг ашигладаг аа. Аа тэгээд энэ нь бас л нөгөө англилал хийх систем өөрөөр сурах үйл явц гэх юм уу тэрнээс өмнө хийдэг.

Энэ уншиж байгаа ажлын онцлог нь энэ үед энэнээс өмнө ингээд шууд загвар луугаа өгөгдлөө боловсруулалт хийлгүй оруулчихдаг аргачлал байгаагүй гэж байна шүү.

За тэгээд гол төвлөрч буй арга нь болохоор CNN, бас multivariate method гээд байгаан юу гэдгийн мэдэх биз ээ хойшоогоо явахдаа.

Аа заза өмнөх машин сургалтын аргачлалуудаас ялгаатай нь болохоор энэ систем дотроо л одоо бодвол тэр data prepocessing, PCA шиг гэж ойлголоо feature extraction болон нөгөө classification буюу ангилах гээд бүх юмаа эндээ багтаацан л юм шиг байна. Ер нь л супер л амьтан гэж яригддаг байждээ энэ үед. Энэ систем гэж CNN architecture аа яриад байгаа шүү. Тэгээд өмнөх үеээ мэдэхгүй юм болохоор сайн буудаггүй ээ гэхдээ бол өмнө нь их л зовж нэг юм гаргадаг байсан юм байна л даа. Тэгээд нөгөөхийн сайжруулах гэж үйл тамаа цайдаг байсан байна юу вэ гэхээр муу ажиллахаар өнөөх hyperparameter буюу тохиргоонуудаа гараар хийдэг байж тэгээд оновчтойг нь сонгодог байсан юм байна. Аа энэ нөхөр гарч ирснээр тэгээл үүнийг гараар хийх шаардлагагүй энэ үедээ л төгс сургалтыг хийдэг болсон гэж үзжээ.

За тэгээл ахиал супер гэдгээ магтжээ. Тэхтээ Раман спектр дээр сайн гэдгээ илүү онцолсон юм байна. Би сайн мэдэхгүй л дээ гэхдээ SVM гээд 3 вектор татаад тэр вектороо олох гэж бас бөөн болдог л санагджийн тэр аргаар ангилал хийснээс хамаагүй илүү шаадаг л гэж байна шүү. Тэгээд энэ чинь ахиад л хэлэхээс урьдчилсан боловсруулалт хийх шаардлагагүй гэдгээрээ тодроод байгаа юм байна. урьдчилсан боловсруулалт хийдэг байж магадгүй гэхдээ энэ baseline correction -гүй сурчаад baseline correction -той сурсан SVM -ээс бол илүү гэдэг юм байна. Аа бас хуучны хэдээсээ бол илүү байх нь ойлгомжтой яагаад SVM нь хуучны хэдийнхээ хамгийн дажгүй нь гээд харьцуулсан чинь хавиргаараа савуулцан юм чинь. Оо нэг юмын дурдахгүй бол болохгүй бололтой тэр нь болохоор аймар хурдан л боловсруулдаг буюу хариу гаргадаг гэж ойлголлоо.

За мэдкүү Раман спектр дахь baseline component гэдэг юмны үүсдэг гол шалтгаан нь fluorescence юм байна. Тэгээд нь энэ их лай болдог. Машин ангилах гэхээр манраагаад байдаг ингэнээ.

Заа тэгж байгаад ойлгоноо байгаа baseline correction оос болоод өмнө нь ямар лаг юм хийсэн хамаагүй лай болно оо л гэжийн тэгээд бүр автомат системийн хувьд бол хэцүү л гэжийн бодвол гараар хийвэл арай гайгү л байдын байхдаа.

За бөөн арга судалжээ тэрийн уншина биз ойлгосонгүй дараа л нарийн үзье. Юунд зориулсан арга вэ гэхээр өнөөх auto baseline correction юм байна ингэхдээ fluorescence subtraction энийг нь бууруулах үүднээс хийсэн аргачлалууд бас байж.

Өөр юмнууд бас судалжээ тэр бас уншинаа дахиж.

Энэ ажил нь Раман спектроскопи -г яаж ашиглах вэ юу хийх вэ гэдгээ мэдэхгүй байгаа мань шиг гаруудад хялбаршуулах, тэгээд бас нэг дараагийн түвшинд нь хүргэх гэж үзсэн гэнээ. Мөн гол асуудал нь baseline correction байдын байна л даа энийг яаж үр дүнтэй шийдэх талаар авч үзсэн гэнээ.

Хэн нь сайн шаажын гэдгийн харьцуулах гэж байна. SVM нь өмнөх хэдээсээ бол илүү нь л гэж байна. За энийг яаж ажилладагийн дурьджээ. SVM нь жижиг тэгээд бас 2-тын ангилалд дажгүй. Өөр судалгааны ажлуудад Non-linear SVM нь RBF (radial basis function уул нь сонсож л байж) болон PCA -г ашиглаад амжилттай байсын байна.

Ангилал нь ихсэхээр худардаг гэнээ. Тэхлээр нь Random forest (RF) энэ ensemble гэдэг юм байдын юу гэх вэ гэхээр олон Decision Tree -үүдийн аль гоёийн сонгоод байдаг гэж ойлгож болно энэ аргачлалаар болохоор их хэмжээний их хэмжээст болохоор дажгүй шүү гэдийн байна. Өө тэгснээ нөгөө хэдээсээ муу үр дүн гаргасан гэнээ. PCA-LDA болон RBF SVM тэй харьцуулсан чинь. Энд яригдсан аргуудаас хамгийн дөхсөн нь болохоор fully connected ANN гэнэ. Тэхтээ ер нь л онол талааасаа бол цаашлаад сугардаг л гэж үздэг гэнээ. Vibrational spectroscopic аргуудыг auto classification хийхэд тохиромжтой гэж үзжээ.

Өмнөх аргууд нь feature engineering эсвэл data preprocess хийх шаардлагатай байсаан. Ангилалын тоо ихсээр хялбархан биш болдог. Том хэмжээний зургийн ангилалд CNN гээд арга сайн байсан болохоор энийг Раман дээр хийгээд үзвэл яах болоо гээд архитектур гаргасан юм байна. Тэгээд бодвол тэр нь амжилттай болсон учраас л одоо яриад байгаа байлгүдээ.

Network architecture

За мэдээж юм хийчлээ тэрийг хэр ажиллаж байгааг үнэлэх, дүгнэх шаардлагатай ингэхдээ болохоор ашигт матмалын RRUF гэдэг өгөгдлийг ашиглаад үр дүнгээ танилцуулжээ. Өмнө нь Nearest Neighbor -г ашиглаж байж. Энэ болохоор тухайн шинж чанараараа ижил төстэй буюу хамгийн ойрын хөршүүдийг нэг ангилалд оруулдаг арга юм. Энэ төсөөтэй байдлаараа болохоороо cosine similarity болон correlation зэргийн авч үзсэн юм байна. Өөр хүний хийсэн ажлаар болохоор Weighted Neighbor(WN) -г ашиглаад энэ датасет дээр acc=84.8% гарсан гэнээ. Энэ нь бодвол сайн л юм шиг байна тимүү. Энийг хийхдээ ангилахын өмнө square root squashing, maximum intensity normalization, sigmoid -г ашигласан юм байна.

Accuracy гаргахдаа болохоор cross-validation -г ашигласан тэхтээ олон туршилтаар. тэнцүү хуваасан гэж л ойлголоо гэхдээ туршилт бүр дээрээ санамсаргүй.

WN нь KNN -г давжээ. (82.1%) байж k=1.

Material and methods

CNN бол текст анализ болон computer vision -нд маш ашиглагдаж байгаа сайн арга. CNN нь feature engineering хийлгүйгээр ямар дата гэдэг нь мэдэгдэхгүй юмыг тодорхойлохдоо сайн ажилладаг non-linear classifier юм байна. Энэ нь хөхтөн амьтны харааны бор гадар хэсгийн эсийн нарийн бүтцээс санааг нь авсан юм байна. Тэгээд энэ яаж ажилладагийг дурьдсан байна. CNN abstract түвшиндээ өгөгдлөлөөс онцлог шинж чанарыг ялган авахад зориулагдсан юм байна. Энгийн CNN архитектур нь болохоор conv layer -үүд,
